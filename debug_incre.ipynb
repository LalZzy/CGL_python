{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from preprocessing import generate_triple, generate_trn, row_normlize, read_file\n",
    "import model\n",
    "from incremental_learning import split_tripple,cal_l0,calc_l1,calc_l2,gene_incre_matrix,incre_cgl_rank_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'data/all_ruc_word_info_new_with_essay.csv'\n",
    "link_file = 'data/all_ruc_new_link_with_essay.csv'\n",
    "concept_file = 'data/ruc_all_concepts_new_with_essay.csv'\n",
    "file_type = 'sparse_row_col_val'\n",
    "incre_course_num = 176\n",
    "incre_concept_num = 137\n",
    "undirect=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, links, concept = read_file(data_file, link_file, concept_file=concept_file, file_type=file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.todense()\n",
    "X = row_normlize(X)\n",
    "n_course, n_concept = X.shape[0], X.shape[1]\n",
    "trn = generate_trn(links, n_course, undirect=undirect)\n",
    "tripple = generate_triple(trn)\n",
    "split_tripple_list = split_tripple(tripple, range(X.shape[0]-incre_course_num,X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, eta: 0.157779 B's 'f-norm' decreases: 1376.477362, old_loss: 33697.824211, current_loss: 32321.346849\n",
      "B change: max=44.61934559388539, min=-21.03476211160803\n",
      "regulazition part=392.175018333372, loss_part=31929.171830278792\n",
      "Iteration: 20, eta: 0.142396 B's 'f-norm' decreases: 205.997013, old_loss: 24463.849063, current_loss: 24257.852050\n",
      "B change: max=40.53648507920489, min=-21.8822499593565\n",
      "regulazition part=317.61849555881986, loss_part=23940.233554260427\n",
      "Iteration: 30, eta: 0.142396 B's 'f-norm' decreases: 193.340217, old_loss: 22701.164021, current_loss: 22507.823803\n",
      "B change: max=38.87024609247464, min=-24.66460833359691\n",
      "regulazition part=307.59866015724845, loss_part=22200.225143075906\n",
      "Iteration: 40, eta: 0.128512 B's 'f-norm' decreases: 88.843325, old_loss: 20986.180381, current_loss: 20897.337056\n",
      "B change: max=37.16819652422308, min=-28.264594774598027\n",
      "regulazition part=309.34630684525825, loss_part=20587.99074906928\n",
      "Iteration: 50, eta: 0.128512 B's 'f-norm' decreases: 110.515869, old_loss: 20240.146637, current_loss: 20129.630768\n",
      "B change: max=36.662573973539736, min=-30.17891536740702\n",
      "regulazition part=321.4050091270738, loss_part=19808.225758794895\n",
      "Iteration: 60, eta: 0.128512 B's 'f-norm' decreases: 133.778321, old_loss: 18993.368602, current_loss: 18859.590281\n",
      "B change: max=39.38774297446569, min=-33.60701246037805\n",
      "regulazition part=346.64337359329977, loss_part=18512.94690724058\n",
      "Iteration: 70, eta: 0.128512 B's 'f-norm' decreases: 125.924277, old_loss: 17677.102098, current_loss: 17551.177821\n",
      "B change: max=48.79258404289511, min=-37.379994846261525\n",
      "regulazition part=386.76670577076555, loss_part=17164.41111503506\n",
      "Iteration: 80, eta: 0.128512 B's 'f-norm' decreases: 110.721650, old_loss: 16485.233607, current_loss: 16374.511957\n",
      "B change: max=59.25889354143589, min=-40.828623296181966\n",
      "regulazition part=439.37159632847863, loss_part=15935.140360751879\n",
      "Iteration: 90, eta: 0.128512 B's 'f-norm' decreases: 95.842154, old_loss: 15446.172210, current_loss: 15350.330056\n",
      "B change: max=70.1004138139328, min=-46.35812163722247\n",
      "regulazition part=498.837726700866, loss_part=14851.49232932267\n",
      "Iteration: 100, eta: 0.128512 B's 'f-norm' decreases: 82.897926, old_loss: 14547.834844, current_loss: 14464.936918\n",
      "B change: max=80.84488923286327, min=-51.7779072840859\n",
      "regulazition part=559.6820295545942, loss_part=13905.254888656871\n",
      "Iteration: 110, eta: 0.128512 B's 'f-norm' decreases: 71.885811, old_loss: 13769.841903, current_loss: 13697.956092\n",
      "B change: max=91.18935175994491, min=-57.12374003226995\n",
      "regulazition part=618.1925529600068, loss_part=13079.763538578776\n",
      "Iteration: 120, eta: 0.128512 B's 'f-norm' decreases: 62.524003, old_loss: 13094.376782, current_loss: 13031.852779\n",
      "B change: max=100.99063304205329, min=-62.03837293818714\n",
      "regulazition part=672.5414279867814, loss_part=12359.311350533262\n",
      "Iteration: 130, eta: 0.128512 B's 'f-norm' decreases: 54.468848, old_loss: 12506.316660, current_loss: 12451.847812\n",
      "B change: max=110.21835916414182, min=-66.51632314599415\n",
      "regulazition part=722.7989772464231, loss_part=11729.048834815254\n",
      "Iteration: 140, eta: 0.128512 B's 'f-norm' decreases: 47.580072, old_loss: 11993.654681, current_loss: 11946.074609\n",
      "B change: max=118.8577163750524, min=-70.61927830664703\n",
      "regulazition part=770.4343865158854, loss_part=11175.64022241187\n",
      "Iteration: 150, eta: 0.128512 B's 'f-norm' decreases: 41.930941, old_loss: 11544.236066, current_loss: 11502.305126\n",
      "B change: max=126.92263497641501, min=-74.38054468235354\n",
      "regulazition part=817.1064520005358, loss_part=10685.198673561814\n",
      "Iteration: 160, eta: 0.128512 B's 'f-norm' decreases: 37.366569, old_loss: 11146.284250, current_loss: 11108.917681\n",
      "B change: max=134.47140119371778, min=-79.77478948182885\n",
      "regulazition part=863.7311287863723, loss_part=10245.186552286135\n",
      "Iteration: 170, eta: 0.128512 B's 'f-norm' decreases: 33.660248, old_loss: 10789.890465, current_loss: 10756.230217\n",
      "B change: max=141.56791304457542, min=-86.91058244996566\n",
      "regulazition part=910.3364829490381, loss_part=9845.89373420918\n",
      "Iteration: 180, eta: 0.128512 B's 'f-norm' decreases: 30.574027, old_loss: 10467.604203, current_loss: 10437.030176\n",
      "B change: max=148.2533711435828, min=-94.1995675086144\n",
      "regulazition part=956.3735551577321, loss_part=9480.656621032816\n",
      "Iteration: 190, eta: 0.128512 B's 'f-norm' decreases: 27.930892, old_loss: 10174.092072, current_loss: 10146.161180\n",
      "B change: max=154.56542647591232, min=-101.65219452960133\n",
      "regulazition part=1001.1405122064467, loss_part=9145.02066755177\n",
      "Iteration: 200, eta: 0.128512 B's 'f-norm' decreases: 25.639587, old_loss: 9905.327084, current_loss: 9879.687498\n",
      "B change: max=160.52817165208086, min=-109.260441698479\n",
      "regulazition part=1044.0526364558325, loss_part=8835.63486143043\n",
      "Iteration: 210, eta: 0.128512 B's 'f-norm' decreases: 23.595577, old_loss: 9658.317574, current_loss: 9634.721997\n",
      "B change: max=166.15339776134272, min=-116.98972295212839\n",
      "regulazition part=1084.8118290809466, loss_part=8549.910168345774\n",
      "Iteration: 220, eta: 0.128512 B's 'f-norm' decreases: 21.758268, old_loss: 9430.784299, current_loss: 9409.026031\n",
      "B change: max=171.455278453764, min=-124.7874674038307\n",
      "regulazition part=1123.3533604298896, loss_part=8285.672670933396\n",
      "Iteration: 230, eta: 0.128512 B's 'f-norm' decreases: 20.111892, old_loss: 9220.769297, current_loss: 9200.657404\n",
      "B change: max=176.44756834189093, min=-132.6050839036184\n",
      "regulazition part=1159.7889150268293, loss_part=8040.868489218034\n",
      "Iteration: 240, eta: 0.128512 B's 'f-norm' decreases: 18.655327, old_loss: 9026.357245, current_loss: 9007.701918\n",
      "B change: max=181.140061078565, min=-140.4050211652302\n",
      "regulazition part=1194.307144425195, loss_part=7813.394773804476\n",
      "Iteration: 250, eta: 0.128512 B's 'f-norm' decreases: 17.375661, old_loss: 8845.696926, current_loss: 8828.321265\n",
      "B change: max=185.54686023506397, min=-148.16245239770075\n",
      "regulazition part=1227.0516951319075, loss_part=7601.269570365756\n",
      "Iteration: 260, eta: 0.128512 B's 'f-norm' decreases: 16.245288, old_loss: 8677.139272, current_loss: 8660.893983\n",
      "B change: max=189.68771454184602, min=-155.86008320179047\n",
      "regulazition part=1258.073592855744, loss_part=7402.820390504519\n",
      "Iteration: 270, eta: 0.128512 B's 'f-norm' decreases: 15.243649, old_loss: 8519.291940, current_loss: 8504.048292\n",
      "B change: max=193.5875472058713, min=-163.4843927756213\n",
      "regulazition part=1287.3737708324477, loss_part=7216.674521095013\n",
      "Iteration: 280, eta: 0.128512 B's 'f-norm' decreases: 14.354468, old_loss: 8370.942972, current_loss: 8356.588504\n",
      "B change: max=201.2331435377189, min=-171.02671816197312\n",
      "regulazition part=1314.9433649885443, loss_part=7041.645138827475\n",
      "Iteration: 290, eta: 0.128512 B's 'f-norm' decreases: 13.560475, old_loss: 8231.042909, current_loss: 8217.482434\n",
      "B change: max=209.17423767312977, min=-178.48188842331123\n",
      "regulazition part=1340.8257643434733, loss_part=6876.656669165041\n",
      "Iteration: 300, eta: 0.128512 B's 'f-norm' decreases: 12.843694, old_loss: 8098.722891, current_loss: 8085.879197\n",
      "B change: max=216.96327764372649, min=-185.84252238252554\n",
      "regulazition part=1365.1518462545105, loss_part=6720.727350986491\n",
      "Iteration: 310, eta: 0.128512 B's 'f-norm' decreases: 12.194477, old_loss: 7973.259544, current_loss: 7961.065066\n",
      "B change: max=224.5977803512867, min=-193.09343072675563\n",
      "regulazition part=1388.1031916775962, loss_part=6572.961874761665\n",
      "Iteration: 320, eta: 0.128512 B's 'f-norm' decreases: 11.605483, old_loss: 7854.014871, current_loss: 7842.409388\n",
      "B change: max=232.07582279591966, min=-200.22027351809177\n",
      "regulazition part=1409.8623892628164, loss_part=6432.546998687865\n",
      "Iteration: 330, eta: 0.128512 B's 'f-norm' decreases: 11.070021, old_loss: 7740.408222, current_loss: 7729.338201\n",
      "B change: max=239.39644654646563, min=-207.21025935664562\n",
      "regulazition part=1430.589923651293, loss_part=6298.748277075643\n",
      "Iteration: 340, eta: 0.128512 B's 'f-norm' decreases: 10.573434, old_loss: 7631.969111, current_loss: 7621.395677\n",
      "B change: max=246.55971380369408, min=-214.05331928368162\n",
      "regulazition part=1450.3716600797256, loss_part=6171.024017163053\n",
      "Iteration: 350, eta: 0.128512 B's 'f-norm' decreases: 10.106508, old_loss: 7528.358752, current_loss: 7518.252244\n",
      "B change: max=253.56650003922005, min=-220.7434388732883\n",
      "regulazition part=1469.2229384902382, loss_part=6049.029305044636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop, iteration: 353, eta: 0.128512 B's 'f-norm' decreases: 9.971586, old_loss: 7498.174603, current_loss: 7488.203017\n",
      "B change: max=255.6383000986713, min=-222.72018528115134\n",
      "regulazition part=1474.6938092278642, loss_part=6013.509207331116\n"
     ]
    }
   ],
   "source": [
    "T = split_tripple_list[0]\n",
    "A, F, st = model.cgl_rank(X[:-incre_course_num, :-incre_concept_num], T, lamb=0.01,\n",
    "                      eta=1, tolerence=10, silence=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = gene_incre_matrix(A, incre_concept_num)\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2254, 2254)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_cgl_rank_new(X, st_idx, tripple, split_tripple_list, A0, lamb, eta, tolerrence=0.00001, silence=False, \n",
    "                   update_A1=False):\n",
    "    '''\n",
    "    增量学习版本，可以支持一门课多个词的输入。\n",
    "    '''\n",
    "    # TODO: 这里需要改\n",
    "    # X1~4分别表示分块矩阵的四块，按行编号。\n",
    "    st = datetime.now()\n",
    "    A = A0.copy()\n",
    "    T,T1,T2,T3,T4,T5,T6,T7 = split_tripple_list\n",
    "    row_st_idx, col_st_idx = st_idx\n",
    "    X1 = X[:row_st_idx, :col_st_idx]\n",
    "    X2 = X[:row_st_idx, col_st_idx:]\n",
    "    X3 = X[row_st_idx:, :col_st_idx]\n",
    "    X4 = X[row_st_idx:, col_st_idx:]\n",
    "    incre_course_num = X.shape[0] - row_st_idx\n",
    "    F = np.matmul(np.matmul(X, A), X.transpose())\n",
    "\n",
    "    # loss function: max( (1-F_ij+F_ik),0 ) square.\n",
    "    def loss_func(x): return max(\n",
    "        (1 - F[x[0], x[1]] + F[x[0], x[2]]), 0)**2\n",
    "    \n",
    "    round_A2 = 0\n",
    "    eta1 = eta\n",
    "    old_loss = np.inf\n",
    "    while True:\n",
    "        F = np.matmul(np.matmul(X, A), X.transpose())\n",
    "        p = A.shape[0] - col_st_idx\n",
    "        # l1,l2的形状跟待更新的A2,A3一样\n",
    "        l1 = calc_l1(A, X, st_idx, F, split_tripple_list)\n",
    "        l2 = calc_l2(A, X, st_idx, F, split_tripple_list)\n",
    "        \n",
    "        if update_A1:\n",
    "            l0 = cal_l0(A, X, st_idx, F, T, T1, T2, T3)\n",
    "        # A1 after this round update.\n",
    "        while True:\n",
    "            F_old = F.copy()\n",
    "            A_old = A.copy()\n",
    "            A[:col_st_idx, col_st_idx:] -= eta1 * (lamb * A[:col_st_idx, col_st_idx:] + l1)\n",
    "            A[col_st_idx:, :col_st_idx] -= eta1 * (lamb * A[col_st_idx:, :col_st_idx] + l2)\n",
    "            if update_A1:\n",
    "                A[:col_st_idx, :col_st_idx] -= eta1 * (lamb * A[:col_st_idx, :col_st_idx] + l0)\n",
    "            F = np.matmul(np.matmul(X, A), X.transpose())\n",
    "            \n",
    "            total1 = 0\n",
    "            correct1 = 0\n",
    "            for i, j, k in T2:\n",
    "                if F[i,j] - F[i,k] > 0:\n",
    "                    correct1 += 1\n",
    "                total1 += 1\n",
    "            \n",
    "            total2 = 0\n",
    "            correct2 = 0\n",
    "            for i,j,k in T3:\n",
    "                if F[i,j] - F[i,k] > 0:\n",
    "                    correct2 += 1\n",
    "                total2 += 1\n",
    "                    \n",
    "            loss_part = sum(list(map(loss_func, T1))) + sum(list(map(loss_func, T2))) + sum(list(map(loss_func, T3))) + sum(list(map(loss_func, T4))) + sum(list(map(loss_func, T5)))+ sum(list(map(loss_func, T6))) + sum(list(map(loss_func, T7)))\n",
    "            if update_A1:\n",
    "                loss_part += sum(list(map(loss_func, T))) \n",
    "            reg_part = lamb/2 * np.sqrt((A[:col_st_idx, col_st_idx:]**2).sum())\n",
    "            cur_loss = loss_part + reg_part\n",
    "            unit_loss_change = (old_loss - cur_loss) / A[:col_st_idx, col_st_idx:].size\n",
    "            loss_change = (old_loss - cur_loss)\n",
    "        \n",
    "            if unit_loss_change < 0:\n",
    "                print('loss_part={}, reg_part={}'.format(loss_part, reg_part))\n",
    "                eta1 *= 0.95\n",
    "                F = F_old.copy()\n",
    "                A = A_old.copy()\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        if not silence:\n",
    "            if round_A2 % 1 == 0:\n",
    "                print('round: {}, eta: {}, loss decrease: {}'.format(round_A2, eta1, loss_change))\n",
    "                print('loss_part={}, reg_part={}'.format(loss_part, reg_part))\n",
    "                print('loss_part in tripple:{}'.format(sum(list(map(loss_func, tripple)))))\n",
    "        round_A2 += 1\n",
    "        if loss_change < tolerrence:\n",
    "            break\n",
    "        old_loss = cur_loss\n",
    "    print('train cost: {} step, final loss: {}, loss_change: {}'.format(round_A2, cur_loss, loss_change))\n",
    "    F = np.matmul(np.matmul(X, A), X.transpose())\n",
    "    ed = datetime.now()\n",
    "    return A, F, (ed-st).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: 0, eta: 0.1, loss decrease: inf\n",
      "loss_part=49608.6105660805, reg_part=0.06685968069834296\n",
      "loss_part in tripple:55679.170401555704\n",
      "round: 1, eta: 0.1, loss decrease: 1530.4603883556774\n",
      "loss_part=48078.10511543277, reg_part=0.11192197274544911\n",
      "loss_part in tripple:54231.9867164443\n",
      "round: 2, eta: 0.1, loss decrease: 1017.5011915185969\n",
      "loss_part=47060.564398134215, reg_part=0.15144775271117583\n",
      "loss_part in tripple:53311.50891391373\n",
      "round: 3, eta: 0.1, loss decrease: 722.1509767062525\n",
      "loss_part=46338.378075285626, reg_part=0.18679389504335148\n",
      "loss_part in tripple:52695.52664323622\n",
      "round: 4, eta: 0.1, loss decrease: 533.6131875381107\n",
      "loss_part=45804.73264075621, reg_part=0.21904088635102986\n",
      "loss_part in tripple:52274.78804831724\n",
      "round: 5, eta: 0.1, loss decrease: 403.69045336776617\n",
      "loss_part=45401.01235314671, reg_part=0.2488751280859767\n",
      "loss_part in tripple:51989.0298653127\n",
      "round: 6, eta: 0.1, loss decrease: 309.7086606367375\n",
      "loss_part=45091.275823309, reg_part=0.2767443290586562\n",
      "loss_part in tripple:51801.118201351994\n",
      "round: 7, eta: 0.1, loss decrease: 239.2332900339461\n",
      "loss_part=44852.01629702051, reg_part=0.3029805835972572\n",
      "loss_part in tripple:51686.70165567772\n",
      "round: 8, eta: 0.1, loss decrease: 184.41947910481395\n",
      "loss_part=44667.57195515928, reg_part=0.32784334002070986\n",
      "loss_part in tripple:51629.588482047206\n",
      "round: 9, eta: 0.1, loss decrease: 140.89429305888916\n",
      "loss_part=44526.653967683524, reg_part=0.3515377568803953\n",
      "loss_part in tripple:51618.06319366305\n",
      "round: 10, eta: 0.1, loss decrease: 105.3912290573935\n",
      "loss_part=44421.2400401368, reg_part=0.374236246216514\n",
      "loss_part in tripple:51643.83817319681\n",
      "round: 11, eta: 0.1, loss decrease: 75.93293121758325\n",
      "loss_part=44345.28527383637, reg_part=0.3960713290603789\n",
      "loss_part in tripple:51700.62367940899\n",
      "round: 12, eta: 0.1, loss decrease: 50.87692613602849\n",
      "loss_part=44294.38726084794, reg_part=0.4171581814562622\n",
      "loss_part in tripple:51783.93591656077\n",
      "round: 13, eta: 0.1, loss decrease: 29.32933328911895\n",
      "loss_part=44265.037496854464, reg_part=0.43758888582015704\n",
      "loss_part in tripple:51890.18446440044\n",
      "round: 14, eta: 0.1, loss decrease: 10.659467148994736\n",
      "loss_part=44254.35817948516, reg_part=0.4574391061247577\n",
      "loss_part in tripple:52016.382033445014\n",
      "loss_part=44260.3002833075, reg_part=0.47677458379546733\n",
      "loss_part=44259.5351378225, reg_part=0.4758053699163951\n",
      "loss_part=44258.853805657855, reg_part=0.47488484587900937\n",
      "loss_part=44258.2476645157, reg_part=0.4740105560552309\n",
      "loss_part=44257.70896485922, reg_part=0.47318016949475755\n",
      "loss_part=44257.23072634783, reg_part=0.47239147352836647\n",
      "loss_part=44256.806654226006, reg_part=0.47164236770401635\n",
      "loss_part=44256.431101856186, reg_part=0.47093085803821694\n",
      "loss_part=44256.09897637263, reg_part=0.4702550515660514\n",
      "loss_part=44255.80569067854, reg_part=0.4696131511741141\n",
      "loss_part=44255.547131163075, reg_part=0.46900345070145066\n",
      "loss_part=44255.31961035887, reg_part=0.4684243302943794\n",
      "loss_part=44255.11981188717, reg_part=0.4678742520018208\n",
      "loss_part=44254.94475641036, reg_part=0.4673517555984717\n",
      "loss_part=44254.791775667734, reg_part=0.46685545462383543\n",
      "loss_part=44254.65847409908, reg_part=0.4663840326257583\n",
      "loss_part=44254.542698079335, reg_part=0.46593623959772573\n",
      "loss_part=44254.44251678217, reg_part=0.46551088859974926\n",
      "loss_part=44254.35619726138, reg_part=0.4651068525532148\n",
      "round: 15, eta: 0.037735360253530734, loss decrease: 0.06871147882338846\n",
      "loss_part=44254.28218405126, reg_part=0.4647230612005782\n",
      "loss_part in tripple:52067.76132960474\n",
      "train cost: 16 step, final loss: 44254.746907112465, loss_change: 0.06871147882338846\n"
     ]
    }
   ],
   "source": [
    "A1, F1, st = incre_cgl_rank_new(X, (n_course-incre_course_num, n_concept-incre_concept_num), tripple, split_tripple_list, A, eta=0.1, lamb=0.01,\n",
    "                        tolerrence=1, update_A1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('result/ruc_A_incre_with_essay_direct_noupdate_A1.txt', A1)\n",
    "np.savetxt('result/ruc_F_incre_with_essay_direct_noupdate_F1.txt', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.78348124e-05, -4.67662476e-06, -1.70331981e-04, ...,\n",
       "        -5.79974912e-04,  0.00000000e+00, -8.42667718e-05],\n",
       "       [ 1.28689770e-04,  1.65182848e-04,  6.91196805e-04, ...,\n",
       "        -4.26344937e-04,  0.00000000e+00, -1.24315008e-04],\n",
       "       [ 3.10425643e-04,  5.58342751e-04,  3.37912826e-03, ...,\n",
       "        -7.42219080e-04,  0.00000000e+00, -1.67519058e-04],\n",
       "       ...,\n",
       "       [-4.35671316e-04, -3.05273623e-04, -1.62924047e-03, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.12214753e-04, -1.13695172e-04, -5.57439166e-04, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
